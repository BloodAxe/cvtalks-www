<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>OpenCV Tutorial - Part 3</title>
<meta name="description" content="A personal blog about computer vision, AI, machine learning and programmin in OpenCV">
<meta name="generator" content="Hugo 0.18" />
<meta property="og:title" content="OpenCV Tutorial - Part 3" />
<meta property="og:description" content="In Part 1 and Part 2 we created base application for our &ldquo;OpenCV Tutorial&rdquo; application. In this part we add video source to process frames using our samples and present the result to user. As usual, you can find source code for this application at github.
Video capture in iOS At this moment (as far as i know) there OpenCV&rsquo;s cv::VideoCapture does not support iOS platform. Therefore we have to use iOS AVFoundation API to setup video capture." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2012-06-27-opencv-tutorial-part-3/" />


<meta property="og:updated_time" content="2012-06-27T00:00:00&#43;00:00"/>










<link rel="dns-prefetch" href="//fonts.googleapis.com" />

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,700,600" type="text/css" media="all" />
<link rel="stylesheet" href="/css/style.css" type="text/css" media="all" />
<script type="text/javascript" src="/js/scripts.js"></script>
<!--[if lt IE 9]>
	<script src="/js/css3-mediaqueries.js"></script>
<![endif]-->
</head>
<body class="home blog mr-right-sb mr-mobile" itemscope="itemscope" itemtype="http://schema.org/WebPage">
	<div class="mr-container mr-container-outer">
		<div class="mr-header-mobile-nav clearfix"></div>
			<header class="mr-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader">
				<div class="mr-container mr-container-inner mr-row clearfix">
					<div class="mr-custom-header clearfix">
						<div class="mr-site-identity">
							<div class="mr-site-logo" role="banner" itemscope="itemscope" itemtype="http://schema.org/Brand">
								<div class="mr-header-text">
									<a class="mr-header-text-link" href="/" title="Computer Vision Talks" rel="home">
										<h1 class="mr-header-title">Computer Vision Talks</h1>
										<h2 class="mr-header-tagline">All you want to know about image processing</h2>
									</a>
								</div>
							</div>
						</div>
					</div>
				</div>
				<div class="mr-main-nav-wrap">
					<nav class="menu" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
	<ul class="menu__list">
		
		
		
			<li class="menu__item "><a class="menu__link" href="/about/">ABOUT ME</a></li>
		
		
	</ul>
</nav>
				</div>
			</header>
		<div class="mr-wrapper clearfix">


<div class="main-content mr-content" role="main" itemprop="mainContentOfPage">
	<article class="post">
		<header class="entry-header clearfix">
			<h1 class="entry-title">OpenCV Tutorial - Part 3</h1>
			<p class="mr-meta entry-meta">
				<svg class="icon icon-time" height="14" viewBox="0 0 16 16" width="14" xmlns="http://www.w3.org/2000/svg"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
				<time class="entry-meta-date updated" datetime="2012-06-27 00:00:00 &#43;0000 UTC">June 27, 2012</time>
			</p>
		</header>
		<div class="entry-content clearfix">
			
			

<p>In <a href="http://computer-vision-talks.com/2012/06/opencv-tutorial-a-collection-of-opencv-samples-for-iphoneipad-part-1/" title="OpenCV Tutorial – a collection of OpenCV samples for iPhone/iPad – Part 1">Part 1</a> and <a href="http://computer-vision-talks.com/2012/06/opencv-tutorial-part-2/" title="OpenCV Tutorial – Part 2">Part 2</a> we created base application for our &ldquo;OpenCV Tutorial&rdquo; application. In this part we add video source to process frames using our samples and present the result to user. As usual, you can find source code for this application at <a href="https://github.com/BloodAxe/OpenCV-Tutorial" title="OpenCV Tutorial Repository">github</a>.</p>

<h2 id="video-capture-in-ios">Video capture in iOS</h2>

<p>At this moment (as far as i know) there OpenCV&rsquo;s cv::VideoCapture does not support iOS platform. Therefore we have to use iOS AVFoundation API to setup video capture. This is more complicated that write cv::VideoCapture(&ldquo;YourVideoFileName.avi&rdquo;) but it&rsquo;s not a rocket science.  There is a great Apple documentation article <a href="http://developer.apple.com/library/ios/#DOCUMENTATION/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html" title="AV Foundation Programming Guide">AV Foundation Programming Guide</a> that i strongly advice you to read. <strong>By the way, before I forget - video capture is not supported on iOS simulator. You&rsquo;ll need real device to test your app!</strong> To manage the capture from a device such as a camera or microphone, you assemble objects to represent inputs and outputs, and use an instance of <code>AVCaptureSession</code> to coordinate the data flow between them. Minimally you need:</p>

<ul>
<li>An instance of <code>AVCaptureDevice</code> to represent the input device, such as a camera or microphone</li>
<li>An instance of a concrete subclass of <code>AVCaptureInput</code> to configure the ports from the input device</li>
<li>An instance of a concrete subclass of <code>AVCaptureOutput</code> to manage the output to a movie file or still image</li>
<li>An instance of <code>AVCaptureSession</code> to coordinate the data flow from the input to the output
<br /></li>
</ul>

<p>To put all things together we introduce VideoSource class which incapsulate initialization and video capture routine. Let&rsquo;s take a look on it&rsquo;s interface:</p>

<pre><code class="language-objectivec">@protocol VideoSourceDelegate 

- (void) frameCaptured:(cv::Mat) frame;

@end

@interface VideoSource : NSObject

@property id delegate;

- (bool) hasMultipleCameras;
- (void) toggleCamera;
- (void) startRunning;
- (void) stopRunning;

@end
</code></pre>

<p>The VideoSourceDelegate protocol defines a callback procedure that user code can handle. The frameCaptured method is called when the frame is received from a camera device. We wrap it in cv::Mat structure for latter use. Initialization of VideoCamera is also not complicated: we create capture session, add video input and video output:</p>

<pre><code class="language-objectivec">- (id) init
{
  if (self = [super init])
  {
    currentCameraIndex = 0;
    session = [[AVCaptureSession alloc] init];
    [session setSessionPreset:AVCaptureSessionPreset640x480];
    captureDevices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];

    AVCaptureDevice *videoDevice = [captureDevices objectAtIndex:0];

    NSError * error;
    captureInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:&amp;error];

    if (error)
    {
      NSLog(@&quot;Couldn't create video input&quot;);
    }

    captureOutput = [[AVCaptureVideoDataOutput alloc] init];
    captureOutput.alwaysDiscardsLateVideoFrames = YES; 

    // Set the video output to store frame in BGRA (It is supposed to be faster)
    NSString* key = (NSString*)kCVPixelBufferPixelFormatTypeKey; 
    NSNumber* value = [NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA]; 
    NSDictionary* videoSettings = [NSDictionary dictionaryWithObject:value forKey:key]; 
    [captureOutput setVideoSettings:videoSettings];    

    /*We create a serial queue to handle the processing of our frames*/
    dispatch_queue_t queue;
    queue = dispatch_queue_create(&quot;com.computer-vision-talks.cameraQueue&quot;, NULL);
    [captureOutput setSampleBufferDelegate:self queue:queue];
    dispatch_release(queue);

    [session addInput:captureInput];
    [session addOutput:captureOutput];
  }

  return self;
}
</code></pre>

<p>Please not that we query all video devices available using the [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo] call to get them all. This feature allows us to toggle between front and rear cameras in runtime. Also we set capture session preset to 640x480 because the larger the image the more it it need to be processed by our algorithms. 640x480 is a good choice. As our last step we configure capture output to pass our frames in BGRA format. For our image processing it&rsquo;s the ideal case. In case when our video source has several video inputs we can toggle between them using toggleCamera method:</p>

<pre><code class="language-objectivec">- (void) toggleCamera
{
  currentCameraIndex++;
  int camerasCount = [captureDevices count];
  currentCameraIndex = currentCameraIndex % camerasCount;

  AVCaptureDevice *videoDevice = [captureDevices objectAtIndex:currentCameraIndex];

  [session beginConfiguration];

  if (captureInput)
  {
    [session removeInput:captureInput];
  }

  NSError * error;
  captureInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:&amp;error];

  if (error)
  {
    NSLog(@&quot;Couldn't create video input&quot;);
  }

  [session addInput:captureInput];
  [session setSessionPreset:AVCaptureSessionPreset640x480];
  [session commitConfiguration];
}
</code></pre>

<p>In this function we cycle through available inputs and add them to capture session (do not forget to remove previous input) and set the capture preset again (just in case). Switching between from and rear camera is initiated by the user by tapping on toggle button (we will talk about it a bit later). Just one thing left - we should implement AVCaptureVideoDataOutputSampleBufferDelegate in our VideoSource class to receive frames from AVFoundation API like this:</p>

<pre><code class="language-objectivec">- (void)captureOutput:(AVCaptureOutput *)captureOutput 
didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer 
       fromConnection:(AVCaptureConnection *)connection 
{ 
  if (!delegate)
    return;

  CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer); 

  /*Lock the image buffer*/
  CVPixelBufferLockBaseAddress(imageBuffer,0); 

  /*Get information about the image*/
  uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddress(imageBuffer); 
  size_t width = CVPixelBufferGetWidth(imageBuffer); 
  size_t height = CVPixelBufferGetHeight(imageBuffer);  
  size_t stride = CVPixelBufferGetBytesPerRow(imageBuffer);
  //NSLog(@&quot;Frame captured: %lu x %lu&quot;, width,height);

  cv::Mat frame(height, width, CV_8UC4, (void*)baseAddress);

  [delegate frameCaptured:frame];

  /*We unlock the  image buffer*/
  CVPixelBufferUnlockBaseAddress(imageBuffer,0);
}
</code></pre>

<p>In this method we obtain raw data in BGRA format from CoreMedia and put them input cv::Mat (no data is copied here). And then we call [delegate frameCaptured:] to inform user code that new frame is available.</p>

<h2 id="displaying-processed-frames">Displaying processed frames</h2>

<p>Since we working with video processing it&rsquo;s obviously to present the result of video processing in real-time on the screen. To secure the appropriate FPS we have to redraw our screen fast. The existing UIImageView control cannot be used here because we&rsquo;ll spent to much time on unnecessary image conversion (cv::Mat to UIImage) and drawing UIImage on the ImageView. For our goal the fastest way to draw the picture is to use OpenGL ES and GLView to draw our bitmap using GPU. In this section i&rsquo;ll show you how to create simple view that able to draw cv::Mat in real-time. To secure this&rsquo;ll UIView and to EAGLContext using it. This allows us to use OpenGL API to draw textured rectangle on top of our view as fast as possible. For user code we expose only single function that is can use:</p>

<pre><code class="language-objectivec">@interface GLESImageView : UIView

- (void)drawFrame:(const cv::Mat&amp;) bgraFrame;

@end
</code></pre>

		</div>
		
<div class="entry-tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="m4.73135 3.3795002q0-.5597-.39604-.9557-.39604-.3961-.95577-.3961-.55974 0-.95578.3961-.39604.396-.39604.9557 0 .5598.39604.9558.39604.3961.95578.3961.55973 0 .95577-.3961.39604-.396.39604-.9558zm11.26865 6.0832q0 .5596998-.39076.9504998l-5.18548 5.196q-.41188.3908-.9610504.3908-.55974 0-.9505-.3908l-7.5511496-7.5616998q-.40132-.3907-.68119-1.0666-.27987-.6759-.27987-1.2357v-4.3934q0-.54920004.40132-.95050004.40132-.4013.9505-.4013h4.39339q.55974 0 1.23565.2799.67591.2798 1.07723.6812l7.55115 7.54060004q.39076.4118.39076.961z"/></svg>
	<ul>
		<li><a href="/tags/opencv/" rel="tag">opencv</a></li>
		<li><a href="/tags/xcode/" rel="tag">xcode</a></li>
		<li><a href="/tags/tutorials/" rel="tag">tutorials</a></li>
		
	</ul>
</div>
	</article>
	
<div class="mr-author-box clearfix">
	<figure class="mr-author-box-avatar">
		<img alt="Eugene Khvedchenya avatar" src="/img/avatar.png" class="avatar avatar-90 photo" height="90" width="90">
	</figure>
	<div class="mr-author-box-header">
		<span class="mr-author-box-name">About Eugene Khvedchenya</span>
	</div>
	<div class="mr-author-box-bio">
		Eugene Khvedchenya is a computer vision developer skilled in high-performance image processing. In his spare time he loves to share his knowledge and thoughts about computer vision and augmented reality
	</div>
</div>

	

	<nav class="mr-post-nav mr-row clearfix" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement">
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-prev">
			<a href="/post/2012-07-07-opencv-tutorial-part-4/" rel="prev"><span>«Previous</span><p>OpenCV Tutorial - Part 4</p></a>
		</div>
		
		
		<div class="mr-col-1-2 mr-post-nav-item mr-post-nav-next">
			<a href="/post/2012-06-24-opencv-tutorial-part-2/" rel="next"><span>Next»</span><p>OpenCV Tutorial - Part 2</p></a>
		</div>
		
	</nav>


	
<div id="mr-comments" class="mr-comments-wrap">
	<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'cvtalks';
    var disqus_identifier = '\/post\/2012-06-27-opencv-tutorial-part-3\/';
    var disqus_title = 'OpenCV Tutorial - Part 3';
    var disqus_url = '\/post\/2012-06-27-opencv-tutorial-part-3\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

</div>

<aside class="mr-sidebar" itemscope="itemscope" itemtype="http://schema.org/WPSideBar">
	
<div class="mr-widget widget_search">
	<form class="search-form" role="search" method="get" action="//google.com/search">
		<label>
			<span class="screen-reader-text">Search for:</span>
			<input type="search" class="search-field" placeholder="SEARCH..." value="" name="q">
		</label>
		<input class="search-submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>

	
<div class="mr-widget widget_recent_entries">
	<h4 class="mr-widget-title"><span class="mr-widget-title-inner">Recent Posts</span></h4>
	<ul>
		
		<li><a href="/post/how-to-write-good-code/">How to write a good code</a></li>
		
		<li><a href="/post/introducing-cloudcv-bootstrap/">Introducing CloudCV bootstrap</a></li>
		
		<li><a href="/post/how-to-debug-nodejs-addons-in-visual-studio/">How to debug node.js addons in Visual Studio</a></li>
		
		<li><a href="/post/hacking-opencv-for-fun-and-profit/">Hacking OpenCV for fun and profit</a></li>
		
		<li><a href="/post/tile-based-image-processing/">Tile-based image processing</a></li>
		
		<li><a href="/post/image-processing-in-your-browser-unit-test-automation/">Image processing in your browser - Unit Test automation</a></li>
		
		<li><a href="/post/computer-vision-digest-september-2014/">Computer Vision Digest - September 2014</a></li>
		
		<li><a href="/post/how-to-convert-args-from-js-to-cpp/">Argument checking for native addons for Node.js. Do it right!</a></li>
		
		<li><a href="/post/computer-vision-digest-august-2014/">Computer Vision Digest - August 2014</a></li>
		
		<li><a href="/post/mapping-eigen-to-opencv/">Mapping data from Eigen to OpenCV and back</a></li>
		
	</ul>
</div>


	




	


<div class="mr-widget widget_tag_cloud">
	<h4 class="mr-widget-title"><span class="mr-widget-title-inner">Tags</span></h4>
	<div class="tagcloud">
		
			<a href="/tags/algorithms" class="tag-link" title="algorithms" style="font-size: 12px;">algorithms</a>
		
			<a href="/tags/ar" class="tag-link" title="ar" style="font-size: 12px;">ar</a>
		
			<a href="/tags/books" class="tag-link" title="books" style="font-size: 12px;">books</a>
		
			<a href="/tags/cloud-computing" class="tag-link" title="cloud-computing" style="font-size: 12px;">cloud-computing</a>
		
			<a href="/tags/cloudcv" class="tag-link" title="cloudcv" style="font-size: 12px;">cloudcv</a>
		
			<a href="/tags/coursera" class="tag-link" title="coursera" style="font-size: 12px;">coursera</a>
		
			<a href="/tags/cpp" class="tag-link" title="cpp" style="font-size: 12px;">cpp</a>
		
			<a href="/tags/digest" class="tag-link" title="digest" style="font-size: 12px;">digest</a>
		
			<a href="/tags/iphone" class="tag-link" title="iphone" style="font-size: 12px;">iphone</a>
		
			<a href="/tags/neon" class="tag-link" title="neon" style="font-size: 12px;">neon</a>
		
			<a href="/tags/news" class="tag-link" title="news" style="font-size: 12px;">news</a>
		
			<a href="/tags/nodejs" class="tag-link" title="nodejs" style="font-size: 12px;">nodejs</a>
		
			<a href="/tags/opencv" class="tag-link" title="opencv" style="font-size: 12px;">opencv</a>
		
			<a href="/tags/reddit" class="tag-link" title="reddit" style="font-size: 12px;">reddit</a>
		
			<a href="/tags/scala" class="tag-link" title="scala" style="font-size: 12px;">scala</a>
		
			<a href="/tags/tutorials" class="tag-link" title="tutorials" style="font-size: 12px;">tutorials</a>
		
			<a href="/tags/visualstudio" class="tag-link" title="visualstudio" style="font-size: 12px;">visualstudio</a>
		
			<a href="/tags/xcode" class="tag-link" title="xcode" style="font-size: 12px;">xcode</a>
		
	</div>
</div>



</aside>
	</div>
		<div class="mr-copyright-wrap">
			<div class="mr-container mr-container-inner clearfix">
				<p class="mr-copyright">&copy; 2017 Computer Vision Talks. Based on <a href="//wordpress.org/themes/mh-magazine-lite/" target="_blank" rel="nofollow noopener noreferrer">MH Magazine lite</a>.</p>
			</div>
		</div>
	</div>

<script>
	var navigation = responsiveNav(".menu", {
		navClass: "menu--collapse",
	});
</script>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-10687369-5', 'auto');
ga('send', 'pageview');
</script>

</body>
</html>