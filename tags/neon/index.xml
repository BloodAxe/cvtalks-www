<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neon on Computer Vision Talks</title>
    <link>/tags/neon/index.xml</link>
    <description>Recent content in Neon on Computer Vision Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/neon/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Success-story: Fueling ARBasketball up with NEON</title>
      <link>/post/2013-06-30-success-story-fueling-arbasketball-up-with-neon/</link>
      <pubDate>Sun, 30 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-06-30-success-story-fueling-arbasketball-up-with-neon/</guid>
      <description>&lt;p&gt;img.pull-left.img-thumbnail(src=&amp;ldquo;arbasketball-logo.jpg&amp;rdquo;,alt=&amp;ldquo;ARBasketball&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;p ARBasketball was one of the first augmented reality-based games in App Store. It has been published in 2010. In these days not many people have even heard about AR. I mean it wasn&amp;rsquo;t so popular as it became now. But there were people who saw the great potential in this growing market. One of them was Konstantin Tarovik, the author of &lt;a href=&#34;https://itunes.apple.com/ru/app/arbasketball-augmented-reality/id393333529?mt=8&#34;&gt;ARBasketball&lt;/a&gt;. I must confess - I saw this application before, but had no idea it&amp;rsquo;s author lives in Ukraine, and in the same city as I am! It was really surprising to discover there is another passionate person in Odessa and is also interested in computer-vision and AR! While I was concentrating on back-end development and most of my projects were under NDA, Konstantin aimed for product development. Actually that was the reason he contacted me&amp;hellip;&lt;/p&gt;

&lt;p&gt;h2 First contact&lt;/p&gt;

&lt;p&gt;p Konstantin contacted me in fall 2012. He wanted me to help him optimize performance of ARBasketball on iOS devices. I agreed, because it was very interesting task and I was happy to help countryman. There were two problems we were going to solve: - Performance - Robustness&lt;/p&gt;

&lt;p&gt;p In computer vision choice of any algorithm is a trade-off between speed and quality: you lower the frame resolution and get more speed, but lose precision; you increase the number of features and get more robust tracking but lose speed, etc. In our case we had an issue that game was not very stable in low-light or in over saturated scenes. The second issue was performance of marker detection algorithm. To provide the best game experience you should have at least 25 fps. In other words, you have only 30 milliseconds to acquire the new frame, find the marker on it, update physics and render the frame. Real-time is always a challenge.&lt;/p&gt;

&lt;p&gt;h2 Wrong way&lt;/p&gt;

&lt;p&gt;p
    | To provide lighting-invariant marker detection I decided to apply &lt;a href=&#34;http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#adaptivethreshold&#34;&gt;adaptive threshold&lt;/a&gt; since this filter can easily deal with non-uniform lighting and it works perfect for low-light cases too. Speed of adaptive threshold depends on window size, in our case the best results were achieved with window size of 7 pixels. Unfortunately, OpenCV implementation of adaptive threshold was too slow and we decided to utilize GPU for thresholding. Unfortunately, the OpenCL technology is not yet supported by iOS devices, so we had to use OpenGL ES 2.0 shaders and textures to simulate GPGPU. A great Brad Larson&amp;rsquo;s library &lt;a href=&#34;https://github.com/BradLarson/GPUImage&#34;&gt;GPUImage&lt;/a&gt; helped us a lot in this. After we performed the test it became clearly visible there is a huge lag when you try to access the result of GPU processing:
    img(src=&amp;ldquo;chart_1-2.png&amp;rdquo;,alt=&amp;ldquo;GPU-accelerated adaptive threshold&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;p While thresholding took less than 5 milliseconds per frame (including gray-scale conversion), the frame download took almost twice more time. This news was really discouraging for us. Of course, I spent a lot of time trying to identify the reason of this lag. It can be a topic for another post, but cutting a long story shorter - the GPU is shared between applications and OS itself. Each application can have multiple GPU contexts (EAGLContext). In GPGPU you can get result of your operation using render-to-texture technique. To get valid results you should call &lt;strong&gt;glFlush&lt;/strong&gt; and &lt;strong&gt;glFinish&lt;/strong&gt; commands before you access your texture. These calls are blocking operations - they force the CPU to wait until GPU pipeline is empty. This synchronization can take really long time. In our case it took almost 10 ms per frame. In addition we have found that low-end devices like iPhone touch or iPhone 4 does not have GPU powerful enough. So we decided to look for an alternative approach.&lt;/p&gt;

&lt;p&gt;h2 NEON comes in scene&lt;/p&gt;

&lt;p&gt;p It was logical that rendering and GPGPU-processing would fight each other for resources. So why not to separate these tasks? Let the whole GPU be occupied with the scene rendering and utilize CPU for image processing. Starting from this point I cannot reveal particular optimization details. But in general we re-designed existing algorithm to process less data and re-wrote most heavy functions with assembly language using NEON SIMD instructions. This was a win:
    ul
        li iPhone3Gs: 24ms per frame
        li iPod touch: 17 ms per frame
        li iPad 2: 8ms per frame
        li iPhone 4S: 8 ms per frame&lt;/p&gt;

&lt;p&gt;p Remember I was talking about speed-quality trade-off? Since we had enough spare time we could spent it to compute final basket pose more precisely. In particular, our algorithm is choosing the optimal pose estimation parameters depending on the current hardware ARBasketball is running on. On low-end hardware pose estimation is not too-precise, but anyway it is still providing smooth 30 FPS gameplay. On modern devices we have more power and can do more work. This adaptive parameter tuning is really helpful when you have to secure the same level of performance on many devices.&lt;/p&gt;

&lt;p&gt;h2 Conclusion&lt;/p&gt;

&lt;p&gt;p Optimize wisely and remember about your environment. Your application cannot not always have 100% of hardware power, besides there are other tasks that require CPU and GPU power: user-interaction handling, 3D rendering, audio decoding, device motion updates, notifications, network, physic simulation, threading. Keep in mind that algorithm you optimize can (and it will) interfere to the environment. It was very interesting to work with Konstantin on ARBasketball and I&amp;rsquo;m glad I had this opportunity.&lt;/p&gt;

&lt;p&gt;p Recently, Paladone has announced &lt;a href=&#34;http://www.ebay.com/itm/AR-BASKETBALL-APP-MUG-Augmented-Reality-Tea-Coffee-Mug-for-iPhone-5-4-3-iPad-/350786629462?pt=UK_HG_Crockery_RL&amp;amp;hash=item51ac832f56&#34;&gt;ARBasketball Mug&lt;/a&gt;. A coffee/tea mug with printed marker on it&amp;rsquo;s side that allow you to play ARBasketball. Really amazing idea. By the way, I&amp;rsquo;ve already got mine ;)&lt;/p&gt;

&lt;p&gt;[4]:&lt;/p&gt;

&lt;p&gt;[6]:&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maximizing performance of CV_BGRA2GRAY conversion using NEON and cv::parallel_for</title>
      <link>/post/2012-11-06-maximizing-performance-grayscale-color-conversion-using-neon-and-cvparallel_for/</link>
      <pubDate>Tue, 06 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/post/2012-11-06-maximizing-performance-grayscale-color-conversion-using-neon-and-cvparallel_for/</guid>
      <description>

&lt;p&gt;I continue playing with powerful NEON engine in iPhone and iPad devices. Recently i bought iPhone 4S that replaced my HTC Mozart and i decided to check how to speed up BGRA to GRAY color conversion procedure using multithreading.
&lt;span class=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Recently Itseez announced a minor release of OpenCV 2.4.3 with a lot of new major features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added universal parallel_for implementation using various backends: TBB, OpenMP, GCD, Concurrency&lt;/li&gt;
&lt;li&gt;Improved OpenCV Manager, new Java samples framework, better camera support on Android,&lt;/li&gt;
&lt;li&gt;opencv2.framework is now iOS6- and iPhone5- (armv7s) compatible.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The rest of changes can be seen here: &lt;a href=&#34;http://code.opencv.org/projects/opencv/wiki/ChangeLog&#34;&gt;http://code.opencv.org/projects/opencv/wiki/ChangeLog&lt;/a&gt;. In the past i wrote a NEON-optimized grayscale conversion algorithm (&lt;a href=&#34;http://computer-vision-talks.com/2011/02/a-very-fast-bgra-to-grayscale-conversion-on-iphone/&#34;&gt;http://computer-vision-talks.com/2011/02/a-very-fast-bgra-to-grayscale-conversion-on-iphone/&lt;/a&gt;) which showed a pretty nice speed-up (About 2x times faster than cv::cvtColor(input, output, CV_BGRA2GRAY)). In this post we will use these results as a baseline and try to write something faster. To be fair we start from defining a set of rules for all implementations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We will process square images of size (8, 10, 12, 14, 16, 18, &amp;hellip;., 1596, 1598, 1600) pixels. Processing small and big images will reveal hidden bottlenecks of each implementation.&lt;/li&gt;
&lt;li&gt;Each image will be processed 1000 to avoid measurement fluctuations.&lt;/li&gt;
&lt;li&gt;The destination image will be preallocated prior the test to exclude memory allocations influence.&lt;/li&gt;
&lt;li&gt;We use mach_absolute_time() to measure processing time. As far as i know it&amp;rsquo;s the most precise measuring method.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our main test method looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef void ConversionFunctionPrototype(const cv::Mat&amp;amp; input, cv::Mat&amp;amp; output);

void testConversion(const cv::Mat&amp;amp; input, int numRuns, int&amp;amp; avgTimeInMicroseconds, ConversionFunctionPrototype conversionFn)
{
    assert(input.type() == CV_8UC4);
    assert(input.empty() == false);

    cv::Mat output(input.size(), CV_8UC1);

    uint64_t conversionStart, conversionFinish;
    uint64_t totalTime = 0;

    for (int i = 0; i &amp;lt; numRuns ; i++)
    {
        conversionStart = mach_absolute_time();
        conversionFn(input, output);
        conversionFinish = mach_absolute_time();

        totalTime += (conversionFinish - conversionStart);
    }

    mach_timebase_info_data_t timebase;
    mach_timebase_info(&amp;amp;timebase);

    avgTimeInMicroseconds = (int) ((double)totalTime * (double)timebase.numer / ((double)timebase.denom * (double)numRuns));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The testConversion function computes the average BGRA2GRAY conversion time of the input image by doing color conversion N times (specified by numRuns argument).&lt;/p&gt;

&lt;h2 id=&#34;opencv-implementation&#34;&gt;OpenCV implementation&lt;/h2&gt;

&lt;p&gt;The reference color conversion function from OpenCV:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static void convert_opencv(const cv::Mat&amp;amp; input, cv::Mat&amp;amp; output)
{
    cv::cvtColor(input, output, CV_BGRA2GRAY);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;arm-neon-using-assembler&#34;&gt;ARM NEON using assembler&lt;/h2&gt;

&lt;p&gt;The old assembler version of NEON-accelerated color conversion from my old post:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static void convert_neon_asm_8px(const cv::Mat&amp;amp; input, cv::Mat&amp;amp; output)
{
    uint8_t __restrict * dest = output.data;
    uint8_t __restrict * src  = input.data;
    int numPixels             = input.total();

    __asm__ volatile(&amp;quot;lsr          %2, %2, #3      \n&amp;quot;
                     &amp;quot;# build the three constants: \n&amp;quot;
                     &amp;quot;mov         r4, #28          \n&amp;quot; // Blue channel multiplier
                     &amp;quot;mov         r5, #151         \n&amp;quot; // Green channel multiplier
                     &amp;quot;mov         r6, #77          \n&amp;quot; // Red channel multiplier
                     &amp;quot;vdup.8      d4, r4           \n&amp;quot;
                     &amp;quot;vdup.8      d5, r5           \n&amp;quot;
                     &amp;quot;vdup.8      d6, r6           \n&amp;quot;
                     &amp;quot;0:                           \n&amp;quot;
                     &amp;quot;# load 8 pixels:             \n&amp;quot;
                     &amp;quot;vld4.8      {d0-d3}, [%1]!   \n&amp;quot;
                     &amp;quot;# do the weight average:     \n&amp;quot;
                     &amp;quot;vmull.u8    q7, d0, d4       \n&amp;quot;
                     &amp;quot;vmlal.u8    q7, d1, d5       \n&amp;quot;
                     &amp;quot;vmlal.u8    q7, d2, d6       \n&amp;quot;
                     &amp;quot;# shift and store:           \n&amp;quot;
                     &amp;quot;vshrn.u16   d7, q7, #8       \n&amp;quot; // Divide q3 by 256 and store in the d7
                     &amp;quot;vst1.8      {d7}, [%0]!      \n&amp;quot;
                     &amp;quot;subs        %2, %2, #1       \n&amp;quot; // Decrement iteration count
                     &amp;quot;bne         0b            \n&amp;quot; // Repeat until iteration count is not zero
                     :
                     : &amp;quot;r&amp;quot;(dest), &amp;quot;r&amp;quot;(src), &amp;quot;r&amp;quot;(numPixels)
                     : &amp;quot;r4&amp;quot;, &amp;quot;r5&amp;quot;, &amp;quot;r6&amp;quot;
                     );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;arm-neon-using-intrinsics&#34;&gt;ARM NEON using intrinsics&lt;/h2&gt;

&lt;p&gt;You know you can write the same code using arm intrinsics? Here it is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static void convert_neon8px_int(const cv::Mat&amp;amp; input, cv::Mat&amp;amp; output)
{
    uint8_t __restrict * dest = output.data;
    uint8_t __restrict * src  = input.data;
    int numPixels             = input.total();

    uint8x8_t rfac = vdup_n_u8 (77);
    uint8x8_t gfac = vdup_n_u8 (151);
    uint8x8_t bfac = vdup_n_u8 (28);

    register int n = numPixels / 8;
    uint16x8_t  temp;
    uint8x8_t result;
    uint8x8x4_t rgb;

    for (register int i = 0; i &amp;lt; n; i++, src += 8*4, dest += 8)
    {
        rgb  = vld4_u8 (src);

        temp = vmull_u8 (rgb.val[0],      rfac);
        temp = vmlal_u8 (temp,rgb.val[1], gfac);
        temp = vmlal_u8 (temp,rgb.val[2], bfac);

        result = vshrn_n_u16 (temp, 8);
        vst1_u8 (dest, result);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;parallel-neon-version&#34;&gt;Parallel NEON version&lt;/h2&gt;

&lt;p&gt;Both &lt;strong&gt;convert_neon_asm_8px&lt;/strong&gt; and &lt;strong&gt;convert_neon8px_int&lt;/strong&gt; functions process 8 pixels at once. This color conversion function is a great candidate for multithreading optimization. Since iPhone 4S and iPad 2 have two Cortex A8 CPU we can run our color conversion in two threads. For this purpose we want to use Grand Central Dispatch mechanism from iOS. It provides easy mechanism to execute tasks in multithreaded environment. OpenCV developers offers new nice feature to perform parallel calculation - &lt;strong&gt;cv::parallel_for&lt;/strong&gt;. This function provides abstraction layer between multithreading backend and user code. To use &lt;strong&gt;cv::parallel_for&lt;/strong&gt; you have to implement a cv::ParallelLoopBody functor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// a base body class
class CV_EXPORTS ParallelLoopBody
{
public:
    virtual ~ParallelLoopBody();
    virtual void operator() (const Range&amp;amp; range) const = 0;
};

CV_EXPORTS void parallel_for_(const Range&amp;amp; range, const ParallelLoopBody&amp;amp; body, double nstripes=-1.);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our color conversion function simply wraps the code from the ARM NEON version with slight modifications. When counting the number of pixels to process we take into account the range argument passed to the function body.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct convert_ParallelLoopBody : public cv::ParallelLoopBody
{
    convert_ParallelLoopBody(const cv::Mat&amp;amp; input, cv::Mat&amp;amp; output)
    : _in(input)
    , _out(output)
    {
    }

    void operator() (const cv::Range&amp;amp; range) const
    {
        uint8_t __restrict * dest = _out.data + range.start;
        uint8_t __restrict * src  = _in.data  + range.start * 4;

        int numPixels             = range.size();

        uint8x8_t rfac = vdup_n_u8 (77);
        uint8x8_t gfac = vdup_n_u8 (151);
        uint8x8_t bfac = vdup_n_u8 (28);

        register int n = numPixels / 8;
        uint16x8_t  temp;
        uint8x8_t result;
        uint8x8x4_t rgb;

        for (register int i = 0; i &amp;lt; n; i++, src += 8*4, dest += 8)
        {
            rgb  = vld4_u8 (src);

            temp = vmull_u8 (rgb.val[0],      rfac);
            temp = vmlal_u8 (temp,rgb.val[1
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>A very fast BGRA to Grayscale conversion on Iphone</title>
      <link>/post/2011-02-08-a-very-fast-bgra-to-grayscale-conversion-on-iphone/</link>
      <pubDate>Tue, 08 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>/post/2011-02-08-a-very-fast-bgra-to-grayscale-conversion-on-iphone/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;NEON_ProductImage.jpg&#34; alt=&#34;&#34; title=&#34;NEON&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Almost all image processing algorithms uses gray scale images as input source. But almost all hardware video sources provide frames in RGB/BGR(A) formats. So gray scale conversion is very popular operation. Although it&amp;rsquo;s expensive enough to cause CPU-bound bottlenecks while running on mobile processors. In this post i will show you how to use ARM NEON intrinsic to get significant performance boost of BGRA to GRAY conversion.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&#34;color-representation&#34;&gt;Color representation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;RGB_illumination.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Pixel color can be presented in different ways. RGB color model presents color as a combination of three base colors of different intensity. Gray scale image contains only pixel luminance value without specific color. Pixels from RGB color model can be converted to gray scale using following formula: Y = 0.2126 R + 0.7152 G + 0.0722 B. Multipliers can very depending on the color space standards. Since we are targeting to iPhone it’s necessary to remember that camera capture from iOS AVFramework provide video frames in BGRA format (alpha channel is always equals to 255). For our further steps we will ignore it.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation:&lt;/h2&gt;

&lt;p&gt;First of all we need reference C++ implementation. Just to know the starting point. Here it is:&lt;/p&gt;

&lt;h4 id=&#34;reference-c-bgra-to-grayscale-conversion-function&#34;&gt;Reference C++ BGRA to Grayscale conversion function:&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static void reference_convert (common::UInt8 * dest, common::UInt8 * src, int n)
{
  int i;
  int r,g,b;
  int y;

  for (i=0; i &amp;lt; n; i++)
  {
    b = *src++; // load blue
    g = *src++; // load green
    r = *src++; // load red
    src++; // skip aplha

    // build weighted average:
    y = (r*77)+(g*151)+(b*28);

    // undo the scale by 256 and write to memory:
    *dest++ = (y&amp;gt;&amp;gt;8);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Okay, this function works relatively fast but not enough. Since iPhone has ARM CPU (Cortex A-9), it supports SIMD NEON engine which can be used for color conversion with great effort. SIMD technology allows process multiple data with one instruction call, saving time for other computations. Cutting a long story shorter – we will process eighth(!) pixels at one time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;NEON_ISA.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Fortunately, you don’t have to deal with such low-level instructions directly. There are special functions, called intrinsic, which can be treated as regular functions but they works with input data simultaneously. If you want to learn more about NEON intrinsic you will found link in the “References” section.&lt;/p&gt;

&lt;h4 id=&#34;arm-neon-intrinsic-optimized-conversion&#34;&gt;ARM NEON Intrinsic-optimized conversion:&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void neon_convert (uint8_t * __restrict dest, uint8_t * __restrict src, int numPixels)
{
  int i;
  uint8x8_t rfac = vdup_n_u8 (77);
  uint8x8_t gfac = vdup_n_u8 (151);
  uint8x8_t bfac = vdup_n_u8 (28);
  int n = numPixels / 8;

  // Convert per eight pixels
  for (i=0; i &amp;lt; n; ++i)
  {
    uint16x8_t  temp;
    uint8x8x4_t rgb  = vld4_u8 (src);
    uint8x8_t result;

    temp = vmull_u8 (rgb.val[0],      bfac);
    temp = vmlal_u8 (temp,rgb.val[1], gfac);
    temp = vmlal_u8 (temp,rgb.val[2], rfac);

    result = vshrn_n_u16 (temp, 8);
    vst1_u8 (dest, result);
    src  += 8*4;
    dest += 8;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function process eight pixels per iteration. Great performance boost but I decided to go further and rewrite anything using assembler. This requires much more knowledge about CPU Architecture but result was worth of it.&lt;/p&gt;

&lt;h2 id=&#34;neon-and-assembler&#34;&gt;NEON and Assembler:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static void neon_asm_convert(uint8_t * __restrict dest, uint8_t * __restrict src, int numPixels)
{
  asm volatile(&amp;quot;lsr          %2, %2, #3      \n&amp;quot;
               &amp;quot;# build the three constants: \n&amp;quot;
               &amp;quot;mov         r4, #28          \n&amp;quot; // Blue channel multiplier
               &amp;quot;mov         r5, #151         \n&amp;quot; // Green channel multiplier
               &amp;quot;mov         r6, #77          \n&amp;quot; // Red channel multiplier
               &amp;quot;vdup.8      d4, r4           \n&amp;quot;
               &amp;quot;vdup.8      d5, r5           \n&amp;quot;
               &amp;quot;vdup.8      d6, r6           \n&amp;quot;
               &amp;quot;.loop:                       \n&amp;quot;
               &amp;quot;# load 8 pixels:             \n&amp;quot;
               &amp;quot;vld4.8      {d0-d3}, [%1]!   \n&amp;quot;
               &amp;quot;# do the weight average:     \n&amp;quot;
               &amp;quot;vmull.u8    q7, d0, d4       \n&amp;quot;
               &amp;quot;vmlal.u8    q7, d1, d5       \n&amp;quot;
               &amp;quot;vmlal.u8    q7, d2, d6       \n&amp;quot;
               &amp;quot;# shift and store:           \n&amp;quot;
               &amp;quot;vshrn.u16   d7, q7, #8       \n&amp;quot; // Divide q3 by 256 and store in the d7
               &amp;quot;vst1.8      {d7}, [%0]!      \n&amp;quot;
               &amp;quot;subs        %2, %2, #1       \n&amp;quot; // Decrement iteration count
               &amp;quot;bne         .loop            \n&amp;quot; // Repeat unil iteration count is not zero
               :
               : &amp;quot;r&amp;quot;(dest), &amp;quot;r&amp;quot;(src), &amp;quot;r&amp;quot;(numPixels)
               : &amp;quot;r4&amp;quot;, &amp;quot;r5&amp;quot;, &amp;quot;r6&amp;quot;
               );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;I’ve done color conversion on 640x512 image (well-known graffiti image) 100 times to get more precise time measures. Here is a chart with graphical illustrations of BGRA to GRAY conversion using different algorithms. I’ve added two 3-rd party implementations (One from OpenCV – cvCvtColor, and one from Boost::Gil – copy_and_convert_pixels) to see how are they optimized. Testing hardware - IPhone 3Gs,  iOS 4.2.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bgra2grayconversion.png&#34; alt=&#34;BGRA to GRAY conversion&#34; title=&#34;BGRA to GRAY conversion&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see, NEON optimized assembler function works three times faster that C++ function with intrinsic and six times faster than pure C++ implementation.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Many thanks for the &lt;a href=&#34;http://hilbert-space.de/?p=22&#34;&gt;Nils Pipenbrinck&lt;/a&gt;. This article helps me a lot!&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.arm.com/software-enablement/161-coding-for-neon-part-1-load-and-stores/&#34;&gt;Coding for NEON - Part 1: Load and Stores&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>