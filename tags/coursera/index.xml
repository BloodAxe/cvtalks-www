<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coursera on Computer Vision Talks</title>
    <link>/tags/coursera/index.xml</link>
    <description>Recent content in Coursera on Computer Vision Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/coursera/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Functional Programming Principles in Scala</title>
      <link>/post/2013-09-17-functional-programming-principles-in-scala/</link>
      <pubDate>Tue, 17 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-09-17-functional-programming-principles-in-scala/</guid>
      <description>&lt;p&gt;img.pull-left.img-thumbnail(src=&amp;ldquo;small-icon.png&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;p
    | Meanwhile, after watching this brilliant talk of the Alexander Soloviov on &amp;ldquo;Functional Reactive Programming and Closure Script&amp;rdquo; i decided to study Functional Programming.
    | Fortunately, there was a active course
    a(href=&amp;ldquo;&lt;a href=&#34;https://class.coursera.org/progfun-003/class/index&amp;quot;&#34;&gt;https://class.coursera.org/progfun-003/class/index&amp;quot;&lt;/a&gt;) Functional Programming Principles in Scala
    |.&lt;/p&gt;

&lt;p&gt;p
    | My first impressions on Scala is&amp;hellip; it&amp;rsquo;s fun!
    | Thinking in functional programming paradigm makes you think different about your objects and their connection to each other.
    | And i&amp;rsquo;m curious how Scala can be used for solving main computer vision problems. I will try to write marker detection algorithm in Scala for curiosity.
    | PS: My russian-speaking readers can watch the inspirational talk on YouTube:
    a(href=&amp;ldquo;&lt;a href=&#34;https://www.youtube.com/watch?v=R4sTvHXkToQ&amp;quot;&#34;&gt;https://www.youtube.com/watch?v=R4sTvHXkToQ&amp;quot;&lt;/a&gt;) &lt;a href=&#34;https://www.youtube.com/watch?v=R4sTvHXkToQ&#34;&gt;https://www.youtube.com/watch?v=R4sTvHXkToQ&lt;/a&gt;
    |.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 1</title>
      <link>/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital/</link>
      <pubDate>Tue, 05 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital/</guid>
      <description>

&lt;p&gt;With this post i start describing my experience with a &lt;a href=&#34;https://www.coursera.org/course/images&#34;&gt;&amp;ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital&amp;rdquo;&lt;/a&gt; class. I will write a series of 9 posts each week i complete and highlight interesting tasks and solution to optional programming quizzes in OpenCV.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;week-1&#34;&gt;Week 1&lt;/h1&gt;

&lt;p&gt;The first week was very easy, just an introduction to image processing with explanation of basics and fundamental things. Took a day to see all video lectures and answer questions.&lt;/p&gt;

&lt;h2 id=&#34;optional-task-average-3x3-blur&#34;&gt;Optional task: Average 3x3 blur&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Task&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Using any programming language you fill comfortable with, perform a simple spatial 3x3 average of image pixels. In other words, replace the value of every pixel by the average of the values in its 3x3 neighborhood. If the pixel is located at (0,0), this means averaging the values of the pixels at the positions (-1,1), (0,1), (1,1), (-1,0), (0,0), (1,0), (-1,-1), (0,-1), and (1,-1). Be careful with pixels at the image boundaries. Repeat the process for a 10x10 neighborhood and again for a 20x20 neighborhood. Observe what happens to the image (we will discuss this in more details in the very near future, about week 3).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Solution&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First of all, there is &lt;a href=&#34;http://docs.opencv.org/modules/imgproc/doc/filtering.html?highlight=blur#void%20blur%28InputArray%20src,%20OutputArray%20dst,%20Size%20ksize,%20Point%20anchor,%20int%20borderType%29&#34;&gt;cv::blur&lt;/a&gt; function that performs what is exactly requested. But to practice, we&amp;rsquo;re gonna to write its our own implementation.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;trivial implementation&lt;/strong&gt; is to traverse over each pixels, and compute NxN sum over each pixel. But that&amp;rsquo;s extremely slow and inefficient solution.&lt;/p&gt;

&lt;p&gt;The most time-consuming operation is calculation of sum of intensities in given area, which has complexity about O(N^2), where N is kernel size. There is a way to perform this operation in O(1) time by using &lt;strong&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Summed_area_table&#34;&gt;integral images**&lt;/a&gt;. In OpenCV we can use **[cv::integral&lt;/strong&gt;]&lt;a href=&#34;http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=integral#void%20integral%28InputArray%20src,%20OutputArray%20sum,%20int%20sdepth%29&#34;&gt;4&lt;/a&gt; function to compute the integral image for given image and then use it to quicly compute sum or elements in particular area.&lt;/p&gt;

&lt;p&gt;So, our algorithm looks as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Take input image&lt;/li&gt;
&lt;li&gt;Create temporary image with padded borders (to handle border case we extend input image by replicating border pixels using &lt;strong&gt;[cv::copyMakeBorder&lt;/strong&gt;]&lt;a href=&#34;http://docs.opencv.org/modules/imgproc/doc/filtering.html?highlight=copymakeborder#void%20copyMakeBorder%28InputArray%20src,%20OutputArray%20dst,%20int%20top,%20int%20bottom,%20int%20left,%20int%20right,%20int%20borderType,%20const%20Scalar&amp;amp;%20value%29&#34;&gt;5&lt;/a&gt; function)&lt;/li&gt;
&lt;li&gt;Compute integral image of it&lt;/li&gt;
&lt;li&gt;Compute sum of each region, divide it by kernel area and write the result to output image&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here is a complete function that performs average sampling using given kernel size. It does perform operation in-place:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void sampleImage(cv::Mat_&amp;lt;unsigned char&amp;gt;&amp;amp; img, int halfKernelSize)
{
    cv::Mat padded;
    cv::copyMakeBorder(img, padded, halfKernelSize, halfKernelSize, halfKernelSize, halfKernelSize, cv::BORDER_REPLICATE);

    cv::Mat_&amp;lt;int&amp;gt; integral;
    cv::integral(padded, integral);

    int sampleArea = (halfKernelSize * 2 + 1) * (halfKernelSize * 2 + 1);

    for (int row = 0; row &amp;lt; img.rows; row++)
    {
        for (int col = 0; col &amp;lt; img.cols; col++)
        {
            int sum = integralSum(integral, row + halfKernelSize, col + halfKernelSize, halfKernelSize);
            img(row, col) = cv::saturate_cast&amp;lt;unsigned char&amp;gt;(sum / sampleArea);
        }
    }
}
&amp;lt;/int&amp;gt;&amp;lt;/unsigned&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The integralSum function calculates the sum of pixel values in a given area (row and cols indicates center of kernel):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int integralSum(cv::Mat_&amp;lt;int&amp;gt;&amp;amp; integralImage, int row, int col, int halfKernelSize)
{
    return + integralImage(row + halfKernelSize + 1, col + halfKernelSize + 1)
           + integralImage(row - halfKernelSize,     col - halfKernelSize)
           - integralImage(row + halfKernelSize + 1, col - halfKernelSize)
           - integralImage(row - halfKernelSize,     col + halfKernelSize + 1);
}
&amp;lt;/int&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running this function on the image gives us following output:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input image&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;fruits.jpg&#34; alt=&#34;Source image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Average blur of 5x5 kernel (grayscale)&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;sampled_gray.png&#34; alt=&#34;Source image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Average blur of 5x5 kernel (color)&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;sampled_rgb.png&#34; alt=&#34;Source image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this solution i didn&amp;rsquo;t posted RGB-version of the algorithm. But the idea is exactly the same. Each color plane is processed independently and then you compute the final RGB pixel value. I leave it for your home work :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image and video processing: From Mars to Hollywood with a stop at the hospital - Week 2</title>
      <link>/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2/</link>
      <pubDate>Tue, 05 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-02-05-image-and-video-processing-from-mars-to-hollywood-with-a-stop-at-the-hospital-week-2/</guid>
      <description>

&lt;p&gt;This is a second part of &lt;a href=&#34;https://www.coursera.org/course/images&#34;&gt;&amp;ldquo;Image and video processing: From Mars to Hollywood with a stop at the hospital&amp;rdquo;&lt;/a&gt; class.&lt;/p&gt;

&lt;p&gt;In optional taks for Week 2 we were asked to test various predictors for JPEG-LS compression algorithm. In this post i want to share my results and discuss how we can achieve better prediction rate.
&lt;span class=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;compare-prediction-algorithms-for-loseless-image-compression&#34;&gt;Compare prediction algorithms for loseless image compression&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Problem statement&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Compute the histogram of a given image and of its prediction errors. If the pixel being processed is at coordinate (0,0), consider predicting based on just the pixel at (-1,0); predicting based on just the pixel at (0,1); predicting based on the average of the pixels at (-1,0), (-1,1), and (0,1). Compute the entropy for each one of the predictors in the previous exercise. Which predictor will compress better?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;A very, very little theory&lt;/strong&gt; So, first of all, JPEG-LS is a lose-less image compression algorithm. It uses variable-length coding (Huffman coding in particular) to minimize the amount of data needed to represent our image. So the idea behind this to predict the next pixel values using values of previous pixels and encode this error instead of pixels itself. So if we guess a lot, the distribution of the error would be non-uniform with a peak in near-zero area. So Huffan coding algorithm will be able reduce the code length.&lt;/p&gt;

&lt;h1 id=&#34;solution&#34;&gt;Solution&lt;/h1&gt;

&lt;p&gt;Based on the entropy of the input image we can describe prediction rate as follows: $$R=H_s / H_e$$, where $$H_s$$ is the entropy of the input image, and $$H_e$$ - is the entropy of the prediction error.&lt;/p&gt;

&lt;p&gt;So, for my tests i wrote a simple OpenCV program that contains predictors test. You can find the full source code here: &lt;strong&gt;&lt;a href=&#34;http://pastebin.com/zWz9vaD7&#34;&gt;http://pastebin.com/zWz9vaD7&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For all the tests i used well-known lena image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;lena.jpg&#34; alt=&#34;lena.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Which has following parameters of the gray-value representation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Std.Dev. 731.663 Entropy: 5.16456&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here i&amp;rsquo;m gonna describe only result of predictors. So we start from trivial predictors that use value of the previous pixel:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int predict_by_previous_pixel_in_row(const cv::Mat_&amp;amp; img, int row, int col)
{
    if (col &amp;gt; 0)
        return img(row, col - 1);
    return 0;
}

int predict_by_previous_pixel_in_col(const cv::Mat_&amp;amp; img, int row, int col)
{
    if (row &amp;gt; 0)
        return img(row - 1, col);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These two predictors give us fair enough prediction rate of ~1.47:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;predict_by_previous_pixel_in_row: Std.Dev. 3322.94 Entropy: 3.50525&lt;/p&gt;

&lt;p&gt;predict_by_previous_pixel_in_col: Std.Dev. 3940.22 Entropy: 3.20661&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then i tried a predictor based on average value of two previous consecutive pixels:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int predict_by_2prev_pixels_in_row(const cv::Mat_&amp;amp; img, int row, int col)
{
    if (col &amp;gt; 1)
        return ((int)img(row, col - 2) + (int)img(row, col - 1)) / 2;
    else
        return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Regarding to the benchmark, this prediction strategy is worth than previous.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;predict_by_2prev_pixels_in_row: Std.Dev. 2908.91 Entropy: 3.70031&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Intuitively it&amp;rsquo;s correct the more pixels we use for prediction, the more precise it will be. And the less prediction error we achieve. The fourth predictor i&amp;rsquo;ve implemented was neighbor averaging predictor:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int predict_by_neighbors(const cv::Mat_&amp;amp; img, int row, int col)
{
    if (col &amp;gt; 0 &amp;amp;&amp;amp; row &amp;gt; 0)
    {
        int a = img(row, col - 1);
        int b = img(row - 1, col - 1);
        int c = img(row - 1, col);
        int s = a + b + c;

        float m = s / 3.0f;
        return (int)m;
    }
    else
        return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It predicts the value of the next pixel by averaging values of it&amp;rsquo;s closest neighbors (top, left and top-left pixel). This predictor shows better results than &lt;strong&gt;predict_by_2prev_pixels_in_row&lt;/strong&gt;, &lt;strong&gt;predict_by_previous_pixel_in_row&lt;/strong&gt;, but for some reason it cannot beat &lt;strong&gt;predict_by_previous_pixel_in_col&lt;/strong&gt; algorithm:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;predict&lt;em&gt;by&lt;/em&gt; neighbors: Std.Dev. 3511.97 Entropy: 3.3431&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then i remembered as Guillermo mentioned that JPEG-LS uses some sort of edge-detection to do this. So i tried to calculate gradient in X and Y directions using neighbor pixel values and compute the prediction using it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int predict_by_gradient(const cv::Mat_&amp;amp; img, int row, int col)
{
    if (col &amp;gt; 0 &amp;amp;&amp;amp; row &amp;gt; 0)
    {
        int a = img(row, col - 1);
        int b = img(row - 1, col - 1);
        int c = img(row - 1, col);

        int gx = a - b;
        int gy = c - b;

        return (int)(b + (gx + gy) / 2.0f);
    }
    else
    {
        return 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, at this moment this algorithm demonstrate the best prediction rate:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;predict_by_gradient: Std.Dev. 3881.62 Entropy: 3.18335&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Can we increase even more? Yes! I think we should use 3x3 neighbor area based prediction for this. I&amp;rsquo;m pretty sure i&amp;rsquo;m reinventing the wheel, but i think it&amp;rsquo;s very fun and useful to train the brain with puzzles like this :) So, does anyone wants to share their predictors? Let&amp;rsquo;s do a small challenge!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Useful information for OpenCV users&lt;/strong&gt;. The source code of my benchmark you can find here: &lt;a href=&#34;http://pastebin.com/zWz9vaD7&#34;&gt;http://pastebin.com/zWz9vaD7&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>